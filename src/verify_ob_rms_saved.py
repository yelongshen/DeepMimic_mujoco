#!/usr/bin/env python3
"""
Verify that ob_rms (observation normalization statistics) are saved in model checkpoint
"""

import torch
import sys
import os

# Add current directory to path
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

from mlp_policy_torch import MlpPolicy
from dp_env_v3 import DPEnv


def check_checkpoint_contents(checkpoint_path):
    """Show what's inside a checkpoint"""
    print("=" * 70)
    print(f"Checkpoint: {checkpoint_path}")
    print("=" * 70)
    
    ckpt = torch.load(checkpoint_path, map_location='cpu')
    
    print("\nAll parameters in checkpoint:")
    print("-" * 70)
    print(f"{'Parameter Name':<35} {'Shape':<20} {'Type'}")
    print("-" * 70)
    
    ob_rms_params = []
    other_params = []
    
    for name, tensor in sorted(ckpt.items()):
        if 'ob_rms' in name:
            ob_rms_params.append((name, tensor))
        else:
            other_params.append((name, tensor))
    
    # Print ob_rms parameters first (highlighted)
    print("\nðŸ” OBSERVATION NORMALIZATION STATISTICS (ob_rms):")
    for name, tensor in ob_rms_params:
        print(f"  âœ“ {name:<33} {str(tensor.shape):<20} {tensor.dtype}")
        if tensor.numel() <= 10:
            print(f"      Values: {tensor.flatten()[:10].tolist()}")
    
    print(f"\nðŸ“Š OTHER MODEL PARAMETERS:")
    for name, tensor in other_params:
        print(f"    {name:<33} {str(tensor.shape):<20} {tensor.dtype}")
    
    print("-" * 70)
    print(f"Total parameters: {len(ckpt)}")
    print(f"ob_rms parameters: {len(ob_rms_params)}")
    print("=" * 70)


def test_save_and_load():
    """Test that ob_rms is saved and loaded correctly"""
    print("\n\n" + "=" * 70)
    print("TEST: Save and Load ob_rms")
    print("=" * 70)
    
    # Create policy
    env = DPEnv()
    policy = MlpPolicy(
        ob_space=env.observation_space,
        ac_space=env.action_space,
        hid_size=64,
        num_hid_layers=2
    )
    
    print("\n1ï¸âƒ£ Initial state (before updating statistics):")
    print(f"   ob_rms.mean[:3] = {policy.ob_rms.mean[:3].numpy()}")
    print(f"   ob_rms.std[:3]  = {policy.ob_rms.std[:3].numpy()}")
    
    # Update statistics with some data
    print("\n2ï¸âƒ£ Updating ob_rms with random observations...")
    fake_obs = torch.randn(100, 56) * 10 + 5  # Random data with mean~5, std~10
    policy.ob_rms.update(fake_obs)
    
    print(f"   ob_rms.mean[:3] = {policy.ob_rms.mean[:3].numpy()}")
    print(f"   ob_rms.std[:3]  = {policy.ob_rms.std[:3].numpy()}")
    
    # Save model
    print("\n3ï¸âƒ£ Saving model to test_checkpoint.pth...")
    torch.save(policy.state_dict(), 'test_checkpoint.pth')
    print("   âœ“ Saved")
    
    # Create new policy and load
    print("\n4ï¸âƒ£ Creating fresh policy (should have default ob_rms)...")
    policy_new = MlpPolicy(
        ob_space=env.observation_space,
        ac_space=env.action_space,
        hid_size=64,
        num_hid_layers=2
    )
    print(f"   ob_rms.mean[:3] = {policy_new.ob_rms.mean[:3].numpy()}")
    print(f"   ob_rms.std[:3]  = {policy_new.ob_rms.std[:3].numpy()}")
    
    # Load checkpoint
    print("\n5ï¸âƒ£ Loading checkpoint...")
    policy_new.load_state_dict(torch.load('test_checkpoint.pth'))
    print(f"   ob_rms.mean[:3] = {policy_new.ob_rms.mean[:3].numpy()}")
    print(f"   ob_rms.std[:3]  = {policy_new.ob_rms.std[:3].numpy()}")
    
    # Verify they match
    print("\n6ï¸âƒ£ Verification:")
    mean_match = torch.allclose(policy.ob_rms.mean, policy_new.ob_rms.mean)
    std_match = torch.allclose(policy.ob_rms.std, policy_new.ob_rms.std)
    
    if mean_match and std_match:
        print("   âœ… SUCCESS! ob_rms statistics were saved and restored correctly!")
    else:
        print("   âŒ FAILED! ob_rms statistics don't match!")
    
    # Cleanup
    os.remove('test_checkpoint.pth')
    print("\n   (Cleaned up test_checkpoint.pth)")
    print("=" * 70)


if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='Verify ob_rms is saved in checkpoint')
    parser.add_argument('--checkpoint', type=str, default='policy_sft_pretrained.pth',
                       help='Path to checkpoint to inspect')
    parser.add_argument('--test', action='store_true',
                       help='Run save/load test')
    
    args = parser.parse_args()
    
    # Check existing checkpoint
    if os.path.exists(args.checkpoint):
        check_checkpoint_contents(args.checkpoint)
    else:
        print(f"Checkpoint not found: {args.checkpoint}")
    
    # Run test if requested
    if args.test:
        test_save_and_load()
    
    print("\n" + "=" * 70)
    print("CONCLUSION:")
    print("=" * 70)
    print("âœ… ob_rms is AUTOMATICALLY saved as part of model.state_dict()")
    print("âœ… It's stored as a 'buffer' (non-trainable parameter)")
    print("âœ… When you load the model, ob_rms statistics are restored")
    print("âœ… This ensures normalization is CONSISTENT between training and inference")
    print("=" * 70)
